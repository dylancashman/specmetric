{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ae6a63",
   "metadata": {},
   "source": [
    "# A Language for Incorporating Data Flow Graphs into Automated Presentation Tools\n",
    "\n",
    "This notebook generates visualizations using the grammar described in submission 6165 for the 2024 CHI conference.\n",
    "\n",
    "## Use Case 1: Model metrics in computational notebook\n",
    "\n",
    "In this use case, we consider a data scientist who has built a model and is trying to communicate the quality of the model using performance metrics.  Using our python package `specmetric`, the data scientist is able to generate visualizations of different metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720e9cf",
   "metadata": {},
   "source": [
    "First, we load the data.  We are using the diabetes data packaged with the scikit learn package.  It features 10 numerical predictors and a diabetes risk score as the predicted label.  Then, we train a linear regression model on that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2e2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "df_X_test = pd.DataFrame(data=diabetes_X_test, columns=['age', 'sex', 'bmi', 'bp', 'tc', 'ldl', 'hdl', 'tch', 'ltg', 'glu'])\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes_y[:-20]\n",
    "diabetes_y_test = diabetes_y[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# Calculate a baseline - always predict the mean label of training set\n",
    "mean_train_labels_baseline = np.full_like(diabetes_y_pred, np.mean(diabetes_y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5978e",
   "metadata": {},
   "source": [
    "Next, we load the specmetric classes.  \n",
    "\n",
    "- `ComputationTreeParser` takes in a data flow graph and parses it, finding visualization preferences.\n",
    "- `ComputationNode` is the object class that describes the data flow graph.\n",
    "- `AltairRenderer` is a visualization recommender that can take in the specifications given out by `ComputationTreeParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc65dea4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(module_path)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load up specmetric\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputationTreeParser\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComputationNode\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrenderer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AltairRenderer\n",
      "File \u001b[1;32m~\\My Drive\\Work\\research\\specmetric_project\\specmetric\\specmetric\\parser.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualization_container\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisualizationContainer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compositions \u001b[38;5;28;01mas\u001b[39;00m _compositions\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grammatical_expressions \u001b[38;5;28;01mas\u001b[39;00m _grammatical_expressions\n",
      "File \u001b[1;32m~\\My Drive\\Work\\research\\specmetric_project\\specmetric\\specmetric\\visualization_container.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrule_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisualizationRule\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compositions \u001b[38;5;28;01mas\u001b[39;00m _compositions\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grammatical_expressions \u001b[38;5;28;01mas\u001b[39;00m _grammatical_expressions\n",
      "File \u001b[1;32m~\\My Drive\\Work\\research\\specmetric_project\\specmetric\\specmetric\\rule_resolver.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compositions \u001b[38;5;28;01mas\u001b[39;00m _compositions\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspecmetric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrules_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grammatical_expressions \u001b[38;5;28;01mas\u001b[39;00m _grammatical_expressions\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVisualizationRule\u001b[39;00m:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Point notebook to local directory to pull in specmetric\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(''))))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Load up specmetric\n",
    "from specmetric.parser import ComputationTreeParser\n",
    "from specmetric.computation_tree import ComputationNode\n",
    "from specmetric.renderer import AltairRenderer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e942fc2",
   "metadata": {},
   "source": [
    "Now that the model is trained and the libraries are loaded, the data scientist calculates some metrics.  We write out these metrics explicitly as a data flow graph.  In practice, it would be possible to write a function that takes Python's abstract syntax tree generated from the scoring functions written by the data scientist.  For this use case, we assume that the AST has already been parsed and written into the DSL that specmetric expects, and the data is all loaded into a dictionary.\n",
    "\n",
    "In the next few cells, we illustrate a few different metrics: r2, mean absolute error, mean squared error, root mean squared error, mean absolute percentage error, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37406ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2\n",
    "\n",
    "########### BEGIN COMPUTATION GRAPH ##########\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; display: block;}</style>\"))\n",
    "\n",
    "y_i = diabetes_y_test\n",
    "ids = np.arange(len(diabetes_y_test))\n",
    "y_hat_i = diabetes_y_pred\n",
    "X = diabetes_X_test\n",
    "y_bar_scalar = np.mean(y_i)\n",
    "y_bar_vector = np.full(y_i.shape, y_bar_scalar)\n",
    "y_i_minus_y_hat_i = y_i - y_hat_i\n",
    "y_i_minus_y_bar = y_i - y_bar_vector\n",
    "y_i_minus_y_hat_i_squared = np.square(y_i_minus_y_hat_i)\n",
    "y_i_minus_y_bar_squared = np.square(y_i_minus_y_bar)\n",
    "ss_res = np.sum(y_i_minus_y_hat_i_squared)\n",
    "ss_tot = np.sum(y_i_minus_y_bar_squared)\n",
    "one = 1\n",
    "ss_res_ss_tot_ratio = ss_res / ss_tot\n",
    "r2 = one - ss_res_ss_tot_ratio\n",
    "data_dict = {\n",
    "    'ids': ids,\n",
    "    'y_i': y_i,\n",
    "    'y_hat_i': y_hat_i,\n",
    "    'X': X,\n",
    "    'y_bar_scalar': y_bar_scalar,\n",
    "    'y_bar_vector': y_bar_vector,\n",
    "    'y_i_minus_y_hat_i': y_i_minus_y_hat_i,\n",
    "    'y_i_minus_y_bar': y_i_minus_y_bar,\n",
    "    'y_i_minus_y_hat_i_squared': y_i_minus_y_hat_i_squared,\n",
    "    'y_i_minus_y_bar_squared': y_i_minus_y_bar_squared,\n",
    "    'ss_res': ss_res,\n",
    "    'ss_tot': ss_tot,\n",
    "    'one': one,\n",
    "    'ss_res_ss_tot_ratio': ss_res_ss_tot_ratio,\n",
    "    'r2': r2\n",
    "}\n",
    "\n",
    "input_vars = ['y_i', 'y_hat_i']\n",
    "for col in df_X_test.columns:\n",
    "    d = df_X_test[[col]]\n",
    "    data_dict[col] = d\n",
    "    input_vars.append(col)\n",
    "\n",
    "minus_scalar = ComputationNode('minus_scalar', None, 'scalar_diff', input_data=['one', 'ss_res_ss_tot_ratio'], output_data='r2')\n",
    "one = ComputationNode('one', minus_scalar, 'scalar', input_data=[], output_data='one')\n",
    "ratio = ComputationNode('ratio', minus_scalar, 'scalar_ratio', input_data=['ss_res', 'ss_tot'], output_data='ss_res_ss_tot_ratio')\n",
    "vector_sum_ss_res = ComputationNode('ss_res', ratio, 'vector_sum',input_data=['y_i_minus_y_hat_i_squared'], output_data='ss_res')\n",
    "vector_sum_ss_tot = ComputationNode('ss_tot', ratio, 'vector_sum', input_data=['y_i_minus_y_bar_squared'], output_data='ss_tot')\n",
    "square_residuals = ComputationNode('square_residuals', vector_sum_ss_res, 'vector_square', input_data=['y_i_minus_y_hat_i'], output_data='y_i_minus_y_hat_i_squared')\n",
    "square_variances = ComputationNode('square_variances', vector_sum_ss_tot, 'vector_square', input_data=['y_i_minus_y_bar'], output_data='y_i_minus_y_bar_squared')\n",
    "vector_difference_residuals = ComputationNode('vector_difference_residuals', square_residuals, 'vector_diff', input_data=['y_i', 'y_hat_i'], output_data='y_i_minus_y_hat_i')\n",
    "vector_difference_variances = ComputationNode('vector_difference_variances', square_variances, 'vector_diff', input_data=['y_i', 'y_bar_vector'], output_data='y_i_minus_y_bar')\n",
    "y_i_var_node = ComputationNode('literal_yi_var', vector_difference_variances, 'vector', output_data='y_i')\n",
    "broadcast = ComputationNode('broadcast_mean', vector_difference_variances, 'broadcast', input_data=['y_bar_scalar', 'y_i'], output_data='y_bar_vector')\n",
    "mean_y = ComputationNode('mean_y', broadcast, 'mean', input_data=['y_i'], output_data='y_bar_scalar')\n",
    "y_i_mean_node = ComputationNode('literal_yi_mean', mean_y, 'vector', output_data='y_i')\n",
    "y_i_res_node = ComputationNode('literal_yi_res', vector_difference_residuals, 'vector', output_data='y_i')\n",
    "y_hat_node = ComputationNode('literal_yhat', vector_difference_residuals, 'vector', output_data='y_hat_i')\n",
    "\n",
    "parser = ComputationTreeParser(minus_scalar)\n",
    "parser.visualizeDFG()\n",
    "vis_containers = parser.visualization_containers\n",
    "########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "charts = r.convert_to_charts()\n",
    "\n",
    "charts.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a47eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute error\n",
    "########### BEGIN COMPUTATION GRAPH ##########\n",
    "## Everything below can be extracted from the abstract syntax tree\n",
    "\n",
    "abs_y_i_minus_y_hat_i = np.abs(y_i_minus_y_hat_i)\n",
    "mean_abs_error = np.mean(abs_y_i_minus_y_hat_i)\n",
    "data_dict['abs_y_i_minus_y_hat_i'] = abs_y_i_minus_y_hat_i\n",
    "data_dict['mean_abs_error'] = mean_abs_error\n",
    "\n",
    "mean = ComputationNode('mean', None, 'mean', input_data=['abs_y_i_minus_y_hat_i'], output_data='mean_abs_error')\n",
    "abs_y_i_minus_y_hat_i_node = ComputationNode('abs_y_i_minus_y_hat_i', mean, 'vector_abs', input_data=['y_i_minus_y_hat_i'], output_data='abs_y_i_minus_y_hat_i')\n",
    "vector_difference_residuals = ComputationNode('vector_difference_residuals', abs_y_i_minus_y_hat_i_node, 'vector_diff', input_data=['y_i', 'y_hat_i'], output_data='y_i_minus_y_hat_i')\n",
    "y_i_res_node = ComputationNode('literal_yi_res', vector_difference_residuals, 'vector', output_data='y_i')\n",
    "y_hat_node = ComputationNode('literal_yhat', vector_difference_residuals, 'vector', output_data='y_hat_i')\n",
    "\n",
    "parser = ComputationTreeParser(mean)\n",
    "parser.visualizeDFG()\n",
    "vis_containers = parser.visualization_containers\n",
    "########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "charts = r.convert_to_charts()\n",
    "\n",
    "charts.display()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "########### BEGIN COMPUTATION GRAPH ##########\n",
    "## Everything below can be extracted from the abstract syntax tree\n",
    "\n",
    "square_y_i_minus_y_hat_i = np.square(y_i_minus_y_hat_i)\n",
    "mean_square_error = np.mean(square_y_i_minus_y_hat_i)\n",
    "data_dict['square_y_i_minus_y_hat_i'] = square_y_i_minus_y_hat_i\n",
    "data_dict['mean_square_error'] = mean_square_error\n",
    "\n",
    "mean = ComputationNode('mean', None, 'mean', input_data=['square_y_i_minus_y_hat_i'], output_data='mean_square_error')\n",
    "square_residuals = ComputationNode('square_y_i_minus_y_hat_i', mean, 'vector_square', input_data=['y_i_minus_y_hat_i'], output_data='square_y_i_minus_y_hat_i')\n",
    "vector_difference_residuals = ComputationNode('vector_difference_residuals', square_residuals, 'vector_diff', input_data=['y_i', 'y_hat_i'], output_data='y_i_minus_y_hat_i')\n",
    "y_i_res_node = ComputationNode('literal_yi_res', vector_difference_residuals, 'vector', output_data='y_i')\n",
    "y_hat_node = ComputationNode('literal_yhat', vector_difference_residuals, 'vector', output_data='y_hat_i')\n",
    "\n",
    "parser = ComputationTreeParser(mean)\n",
    "parser.visualizeDFG()\n",
    "vis_containers = parser.visualization_containers\n",
    "########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "charts = r.convert_to_charts()\n",
    "\n",
    "charts.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "########### BEGIN COMPUTATION GRAPH ##########\n",
    "## Everything below can be extracted from the abstract syntax tree\n",
    "\n",
    "root_mean_square_error = np.sqrt(mean_square_error)\n",
    "data_dict['root_mean_square_error'] = root_mean_square_error\n",
    "\n",
    "root = ComputationNode('root', None, 'scalar_sqrt', input_data=['mean_square_error'], output_data='root_mean_square_error')\n",
    "mean = ComputationNode('mean', root, 'mean', input_data=['square_y_i_minus_y_hat_i'], output_data='mean_square_error')\n",
    "square_residuals = ComputationNode('square_y_i_minus_y_hat_i', mean, 'vector_square', input_data=['y_i_minus_y_hat_i'], output_data='square_y_i_minus_y_hat_i')\n",
    "vector_difference_residuals = ComputationNode('vector_difference_residuals', square_residuals, 'vector_diff', input_data=['y_i', 'y_hat_i'], output_data='y_i_minus_y_hat_i')\n",
    "y_i_res_node = ComputationNode('literal_yi_res', vector_difference_residuals, 'vector', output_data='y_i')\n",
    "y_hat_node = ComputationNode('literal_yhat', vector_difference_residuals, 'vector', output_data='y_hat_i')\n",
    "\n",
    "parser = ComputationTreeParser(root)\n",
    "parser.visualizeDFG()\n",
    "vis_containers = parser.visualization_containers\n",
    "########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "charts = r.convert_to_charts()\n",
    "\n",
    "charts.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute percentage error\n",
    "\n",
    "########### BEGIN COMPUTATION GRAPH ##########\n",
    "## Everything below can be extracted from the abstract syntax tree\n",
    "\n",
    "EPSILON=1e-1\n",
    "abs_y_i = np.maximum(y_i, np.full_like(y_i, EPSILON))\n",
    "ape = abs_y_i_minus_y_hat_i / abs_y_i\n",
    "mape = np.mean(ape)\n",
    "data_dict['abs_y_i'] = abs_y_i\n",
    "data_dict['ape'] = ape\n",
    "data_dict['mape'] = mape\n",
    "\n",
    "mean = ComputationNode('mean', None, 'mean', input_data=['ape'], output_data='mape')\n",
    "ape_node = ComputationNode('ape', mean, 'vector_ratio', input_data=['abs_y_i_node', 'abs_y_i_minus_y_hat_i'], output_data='ape')\n",
    "\n",
    "abs_y_i_minus_y_hat_i_node = ComputationNode('abs_y_i_minus_y_hat_i', ape_node, 'vector_abs', input_data=['y_i_minus_y_hat_i'], output_data='abs_y_i_minus_y_hat_i')\n",
    "vector_difference_residuals = ComputationNode('vector_difference_residuals', abs_y_i_minus_y_hat_i_node, 'vector_diff', input_data=['y_i', 'y_hat_i'], output_data='y_i_minus_y_hat_i')\n",
    "y_i_res_node = ComputationNode('literal_yi_res', vector_difference_residuals, 'vector', output_data='y_i')\n",
    "y_hat_node = ComputationNode('literal_yhat', vector_difference_residuals, 'vector', output_data='y_hat_i')\n",
    "\n",
    "abs_y_i_node = ComputationNode('abs_y_i', ape_node, 'vector_abs', input_data=['y_i'], output_data='abs_y_i')\n",
    "y_i_den_node = ComputationNode('literal_yi_den', abs_y_i_node, 'vector', output_data='y_i')\n",
    "\n",
    "parser = ComputationTreeParser(mean)\n",
    "parser.visualizeDFG()\n",
    "vis_containers = parser.visualization_containers\n",
    "########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "charts = r.convert_to_charts()\n",
    "\n",
    "charts.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df871d",
   "metadata": {},
   "source": [
    "## Additional Calculations and Figures\n",
    "\n",
    "In the following cells, we run various calculations for the figures and examples in the paper.  In the next cell, we calculate the r2 value for the toy dataset used in the r2 motivating example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4b189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2 for the figure\n",
    "coords = [(233.0, 197.0),\n",
    "          (91.0, 155.0),\n",
    "          (111.0, 172.0),\n",
    "          (152.0, 111.0)]\n",
    "\n",
    "df = pd.DataFrame(data=coords, columns=['y_hat_i', 'y_i'])\n",
    "y_bar = df.y_i.mean()\n",
    "r2 = 1 - ((np.sum(np.square(df.y_i - df.y_hat_i))) / (np.sum(np.square(df.y_i - y_bar))))\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b046c",
   "metadata": {},
   "source": [
    "Next, we generate the figures for figure 5 by generating visualizations for different subgraphs within the r2 calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_from_node(n, data_dict, input_vars):    \n",
    "    parser = ComputationTreeParser(n)\n",
    "    parser.visualizeDFG()\n",
    "    vis_containers = parser.visualization_containers\n",
    "    ########### END COMPUTATION GRAPH ##########\n",
    "\n",
    "    r = AltairRenderer(vis_containers, data_dict, input_vars=input_vars)\n",
    "    charts = r.convert_to_charts()\n",
    "\n",
    "    charts.display()\n",
    "\n",
    "vis_from_node(mean_y, data_dict, input_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_from_node(vector_difference_variances, data_dict, input_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_from_node(square_variances, data_dict, input_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on H Chase Stevens `show_ast` package\n",
    "# https://github.com/hchasestevens/show_ast\n",
    "\n",
    "import ast\n",
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def myshowast(__, cell):\n",
    "    m = ast.parse(cell)\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%showast\n",
    "vis_from_node(square_variances, data_dict, input_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ab9a17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
